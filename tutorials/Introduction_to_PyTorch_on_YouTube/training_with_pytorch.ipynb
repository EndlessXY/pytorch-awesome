{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with PyTorch 使用 PyTorch 进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观看[yotube视频](https://www.youtube.com/watch?v=jF43_wj_DCQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "\n",
    "在之前的视频中，我们讨论并演示了：\n",
    "\n",
    "- 使用 `torch.nn` 模块中的神经网络层和函数来构建模型\n",
    "- 自动梯度计算的机制，这是基于梯度的模型训练的核心\n",
    "- 使用 TensorBoard 来可视化训练进展和其他活动\n",
    "\n",
    "在本视频中，我们将为你的工具库添加一些新工具：\n",
    "\n",
    "- 我们将熟悉数据集和数据加载器抽象，以及它们如何简化在训练循环中为模型提供数据的过程\n",
    "- 我们将讨论特定的损失函数以及何时使用它们\n",
    "- 我们将研究 PyTorch 优化器，它实现了根据损失函数的结果调整模型权重的算法\n",
    "\n",
    "最后，我们将把所有这些组合在一起，展示完整的 PyTorch 训练循环的实际应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集与数据加载器\n",
    "\n",
    "`Dataset` 和 `DataLoader` 类封装了从存储中提取数据并将其暴露给训练循环的过程。\n",
    "\n",
    "- `Dataset` 负责访问和处理单个数据实例。\n",
    "- `DataLoader` 从 `Dataset` 中提取数据实例（可以自动完成或通过定义的采样器），将它们收集成批，并返回供训练循环使用。`DataLoader` 可以处理所有类型的数据集，不论它们包含何种类型的数据。\n",
    "\n",
    "在这个教程中，我们将使用 TorchVision 提供的 Fashion-MNIST 数据集。我们使用 `torchvision.transforms.Normalize()` 来对图像内容进行零中心化和标准化处理，并下载训练和验证数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "data_path = os.path.expanduser(\"~/Data/Vision/FashionMNIST\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST(data_path, train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST(data_path, train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据可视化作为健全性检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt  Shirt  Coat  Ankle Boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型\n",
    "\n",
    "在这个示例中我们使用的模型是 LeNet-5 的变体 —— 如果你已经观看了本系列之前的视频，它应该很熟悉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "在这个示例中，我们将使用交叉熵损失。为了演示的目的，我们将创建一些虚拟输出和标签值，并将它们通过损失函数，然后检查结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4070, 0.0985, 0.3708, 0.7122, 0.1880, 0.6242, 0.7090, 0.5607, 0.5170,\n",
      "         0.1250],\n",
      "        [0.9666, 0.0143, 0.7458, 0.6594, 0.0675, 0.6823, 0.3238, 0.3263, 0.1322,\n",
      "         0.0732],\n",
      "        [0.1993, 0.0415, 0.6976, 0.4906, 0.1774, 0.2374, 0.1397, 0.9056, 0.7257,\n",
      "         0.2410],\n",
      "        [0.6188, 0.1370, 0.2332, 0.0567, 0.3781, 0.7456, 0.4332, 0.0430, 0.5304,\n",
      "         0.5670]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.407946825027466\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "在这个示例中，我们将使用简单的 **带动量的随机梯度下降**。\n",
    "\n",
    "可以尝试对该优化方案进行一些变化：\n",
    "\n",
    "- 学习率决定了优化器每次更新权重的步长。不同的学习率对训练结果（准确率和收敛时间）有什么影响？\n",
    "- 动量在多个步骤中将优化器向最强梯度的方向推进。改变该值会对结果产生什么影响？\n",
    "- 尝试使用不同的优化算法，如平均SGD、Adagrad 或 Adam。它们的结果有什么不同？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练循环\n",
    "\n",
    "下面是一个执行一个训练周期的函数。它从 `DataLoader` 中获取数据，并在每次循环时执行以下操作：\n",
    "\n",
    "- 从 `DataLoader` 中获取一批训练数据\n",
    "- 将优化器的梯度清零\n",
    "- 执行推理操作 —— 即获取模型对输入批次的预测\n",
    "- 计算这组预测结果与数据集标签之间的损失\n",
    "- 根据学习权重计算反向梯度\n",
    "- 告诉优化器执行一次学习步骤 —— 即根据观察到的梯度调整模型的学习权重\n",
    "- 每1000批报告一次损失\n",
    "- 最后，报告最后1000批的平均每批损失，用于与验证运行进行比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每个 Epoch 的活动\n",
    "\n",
    "每个 Epoch 完成后，我们需要执行以下几项操作：\n",
    "\n",
    "- 通过检查未用于训练的数据集上的相对损失来执行验证，并报告结果\n",
    "- 保存模型的副本\n",
    "\n",
    "这里，我们将在 TensorBoard 中进行报告。为此，我们需要进入命令行启动 TensorBoard，并在另一个浏览器标签中打开它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.901177402690053\n",
      "  batch 2000 loss: 0.8780766501948237\n",
      "  batch 3000 loss: 0.728695961739868\n",
      "  batch 4000 loss: 0.6444999854215421\n",
      "  batch 5000 loss: 0.6016919274502434\n",
      "  batch 6000 loss: 0.5802384046618827\n",
      "  batch 7000 loss: 0.572995180210215\n",
      "  batch 8000 loss: 0.5105441415755777\n",
      "  batch 9000 loss: 0.48245165446284227\n",
      "  batch 10000 loss: 0.4790531073939055\n",
      "  batch 11000 loss: 0.4673302624820499\n",
      "  batch 12000 loss: 0.4474046237405273\n",
      "  batch 13000 loss: 0.4428332263348857\n",
      "  batch 14000 loss: 0.44363273066078546\n",
      "  batch 15000 loss: 0.42238903905585173\n",
      "LOSS train 0.42238903905585173 valid 0.5170979499816895\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.40829286965017675\n",
      "  batch 2000 loss: 0.40010300725942943\n",
      "  batch 3000 loss: 0.39529749495198485\n",
      "  batch 4000 loss: 0.3769397274689982\n",
      "  batch 5000 loss: 0.36115959496368305\n",
      "  batch 6000 loss: 0.38121517101346397\n",
      "  batch 7000 loss: 0.3749814493315062\n",
      "  batch 8000 loss: 0.3579688208070802\n",
      "  batch 9000 loss: 0.3699201780717121\n",
      "  batch 10000 loss: 0.3678262346960255\n",
      "  batch 11000 loss: 0.36738558095516055\n",
      "  batch 12000 loss: 0.35969034407062284\n",
      "  batch 13000 loss: 0.35167637514462696\n",
      "  batch 14000 loss: 0.342203653623088\n",
      "  batch 15000 loss: 0.32376384118289936\n",
      "LOSS train 0.32376384118289936 valid 0.35727256536483765\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.33607232816072063\n",
      "  batch 2000 loss: 0.33570231627536123\n",
      "  batch 3000 loss: 0.3217543490017997\n",
      "  batch 4000 loss: 0.314143115337949\n",
      "  batch 5000 loss: 0.3132567425440793\n",
      "  batch 6000 loss: 0.319019917803962\n",
      "  batch 7000 loss: 0.3262636732798637\n",
      "  batch 8000 loss: 0.32384979506538364\n",
      "  batch 9000 loss: 0.31133675779160697\n",
      "  batch 10000 loss: 0.29643585525779054\n",
      "  batch 11000 loss: 0.31463333005991445\n",
      "  batch 12000 loss: 0.3177158945655101\n",
      "  batch 13000 loss: 0.31929844610045255\n",
      "  batch 14000 loss: 0.3128882819930441\n",
      "  batch 15000 loss: 0.312999952344333\n",
      "LOSS train 0.312999952344333 valid 0.3205831050872803\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.3074615689685452\n",
      "  batch 2000 loss: 0.2907119816516988\n",
      "  batch 3000 loss: 0.29099805540147006\n",
      "  batch 4000 loss: 0.26550568912844574\n",
      "  batch 5000 loss: 0.3140715507097484\n",
      "  batch 6000 loss: 0.27161746144811694\n",
      "  batch 7000 loss: 0.2963520789988143\n",
      "  batch 8000 loss: 0.2809876176522084\n",
      "  batch 9000 loss: 0.3069855730432173\n",
      "  batch 10000 loss: 0.2957036729217507\n",
      "  batch 11000 loss: 0.2777334216540239\n",
      "  batch 12000 loss: 0.2976839631240873\n",
      "  batch 13000 loss: 0.2926150300474619\n",
      "  batch 14000 loss: 0.2697145157444429\n",
      "  batch 15000 loss: 0.2986192226089697\n",
      "LOSS train 0.2986192226089697 valid 0.3303883671760559\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.27896202834802536\n",
      "  batch 2000 loss: 0.25505120426361466\n",
      "  batch 3000 loss: 0.29231963118558635\n",
      "  batch 4000 loss: 0.27740549915590873\n",
      "  batch 5000 loss: 0.27496339342003195\n",
      "  batch 6000 loss: 0.2646720021888832\n",
      "  batch 7000 loss: 0.2632527217366969\n",
      "  batch 8000 loss: 0.2605698696604959\n",
      "  batch 9000 loss: 0.2607463153628523\n",
      "  batch 10000 loss: 0.27244878538489503\n",
      "  batch 11000 loss: 0.27618768920008185\n",
      "  batch 12000 loss: 0.27562538319024793\n",
      "  batch 13000 loss: 0.29227032982621315\n",
      "  batch 14000 loss: 0.25567219246003153\n",
      "  batch 15000 loss: 0.27773258365578385\n",
      "LOSS train 0.27773258365578385 valid 0.31630194187164307\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'models/model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要加载模型的保存版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦你加载了模型，它就可以用于任何你需要的任务了——无论是继续训练、推理，还是进行分析。\n",
    "\n",
    "需要注意的是，如果你的模型在构造函数中有影响模型结构的参数，那么你需要提供这些参数，并将模型配置为与保存时的状态完全相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他资源\n",
    "\n",
    "- PyTorch 官方文档中的 [数据工具](https://pytorch.org/docs/stable/data.html)，包括 Dataset 和 DataLoader\n",
    "- 关于 [GPU 训练中使用固定内存](https://pytorch.org/docs/stable/notes/cuda.html#use-of-pinned-memory) 的说明\n",
    "- 关于 [TorchVision](https://pytorch.org/vision/stable/datasets.html), [TorchText](https://pytorch.org/text/stable/datasets.html), 和 [TorchAudio](https://pytorch.org/audio/stable/index.html) 的数据集文档\n",
    "- PyTorch 中可用的 [损失函数](https://pytorch.org/docs/stable/nn.html#loss-functions) 文档\n",
    "- [torch.optim](https://pytorch.org/docs/stable/optim.html) 包的文档，其中包括优化器和相关工具，如学习率调度\n",
    "- 详细的 [保存和加载模型的教程](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "- PyTorch 教程部分提供了关于分类、生成对抗网络、强化学习等领域的大量训练任务的 [教程](https://pytorch.org/tutorials/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
